{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WPILib ML Training Notebook\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "By using this notebook, you can train a TensorFlow Lite model for use on a Raspberry Pi and Google Coral USB Accelerator. We've designed this process to be as simple as possible. If you find an issue with this notebook, please create a new issue report on our [GitHub page](https://github.com/wpilibsuite/CoralSagemaker), where you downloaded this notebook.\n",
    "\n",
    "Complete instructions on how to train a model can be found [here](https://docs.wpilib.org/en/latest/docs/software/examples-tutorials/machine-learning/index.html).\n",
    "\n",
    "The code below will take longer depending on your value for 'epochs'. A higher value will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-02 05:02:53 Starting - Starting the training job...\n",
      "2020-06-02 05:02:55 Starting - Launching requested ML instances......\n",
      "2020-06-02 05:04:08 Starting - Preparing the instances for training...\n",
      "2020-06-02 05:04:51 Downloading - Downloading input data\n",
      "2020-06-02 05:04:51 Training - Downloading the training image.........\n",
      "2020-06-02 05:06:12 Training - Training image download completed. Training in progress.\u001b[34m.\u001b[0m\n",
      "\u001b[34mDownloading model.\u001b[0m\n",
      "\u001b[34mSuccessfully created the TFRecords: /opt/ml/input/data/training/train.record.\u001b[0m\n",
      "\u001b[34mSuccessfully created the TFRecords: /opt/ml/input/data/training/eval.record.\u001b[0m\n",
      "\u001b[34mRecords generated.\u001b[0m\n",
      "\u001b[34mHyperparameters parsed.\u001b[0m\n",
      "\u001b[34m+ num_training_steps=500\u001b[0m\n",
      "\u001b[34m+ [[ 4 -gt 0 ]]\u001b[0m\n",
      "\u001b[34m+ case \"$1\" in\u001b[0m\n",
      "\u001b[34m+ num_training_steps=200\u001b[0m\n",
      "\u001b[34m+ shift 2\u001b[0m\n",
      "\u001b[34m+ [[ 2 -gt 0 ]]\u001b[0m\n",
      "\u001b[34m+ case \"$1\" in\u001b[0m\n",
      "\u001b[34m+ num_eval_steps=100\u001b[0m\n",
      "\u001b[34m+ shift 2\u001b[0m\n",
      "\u001b[34m+ [[ 0 -gt 0 ]]\u001b[0m\n",
      "\u001b[34m+ source /tensorflow/models/research/constants.sh\u001b[0m\n",
      "\u001b[34m++ declare -A ckpt_link_map\u001b[0m\n",
      "\u001b[34m++ declare -A ckpt_name_map\u001b[0m\n",
      "\u001b[34m++ declare -A config_filename_map\u001b[0m\n",
      "\u001b[34m++ ckpt_link_map[\"mobilenet_v1_ssd\"]=http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\u001b[0m\n",
      "\u001b[34m++ ckpt_link_map[\"mobilenet_v2_ssd\"]=http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\u001b[0m\n",
      "\u001b[34m++ ckpt_name_map[\"mobilenet_v1_ssd\"]=ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18\u001b[0m\n",
      "\u001b[34m++ ckpt_name_map[\"mobilenet_v2_ssd\"]=ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03\u001b[0m\n",
      "\u001b[34m++ config_filename_map[\"mobilenet_v1_ssd-true\"]=pipeline_mobilenet_v1_ssd_retrain_whole_model.config\u001b[0m\n",
      "\u001b[34m++ config_filename_map[\"mobilenet_v1_ssd-false\"]=pipeline_mobilenet_v1_ssd_retrain_last_few_layers.config\u001b[0m\n",
      "\u001b[34m++ config_filename_map[\"mobilenet_v2_ssd-true\"]=pipeline_mobilenet_v2_ssd_retrain_whole_model.config\u001b[0m\n",
      "\u001b[34m++ config_filename_map[\"mobilenet_v2_ssd-false\"]=pipeline_mobilenet_v2_ssd_retrain_last_few_layers.config\u001b[0m\n",
      "\u001b[34m++ INPUT_TENSORS=normalized_input_image_tensor\u001b[0m\n",
      "\u001b[34m++ OUTPUT_TENSORS=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\u001b[0m\n",
      "\u001b[34m++ OBJ_DET_DIR=/tensorflow/models/research\u001b[0m\n",
      "\u001b[34m++ LEARN_DIR=/tensorflow/models/research/learn\u001b[0m\n",
      "\u001b[34m++ CKPT_DIR=/tensorflow/models/research/learn/ckpt\u001b[0m\n",
      "\u001b[34m++ TRAIN_DIR=/tensorflow/models/research/learn/train\u001b[0m\n",
      "\u001b[34m++ OUTPUT_DIR=/tensorflow/models/research/learn/models\u001b[0m\n",
      "\u001b[34m+ mkdir /tensorflow/models/research/learn/train\u001b[0m\n",
      "\u001b[34m+ python object_detection/model_main.py --pipeline_config_path=/tensorflow/models/research/learn/ckpt/pipeline.config --model_dir=/tensorflow/models/research/learn/train --num_train_steps=200 --num_eval_steps=100\u001b[0m\n",
      "\u001b[34m/tensorflow/models/research/object_detection/utils/visualization_utils.py:26: UserWarning: \u001b[0m\n",
      "\u001b[34mThis call to matplotlib.use() has no effect because the backend has already\u001b[0m\n",
      "\u001b[34mbeen chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\u001b[0m\n",
      "\u001b[34mor matplotlib.backends is imported for the first time.\n",
      "\u001b[0m\n",
      "\u001b[34mThe backend was *originally* set to 'TkAgg' by the following code:\n",
      "  File \"object_detection/model_main.py\", line 26, in <module>\n",
      "    from object_detection import model_lib\n",
      "  File \"/tensorflow/models/research/object_detection/model_lib.py\", line 27, in <module>\n",
      "    from object_detection import eval_util\n",
      "  File \"/tensorflow/models/research/object_detection/eval_util.py\", line 27, in <module>\n",
      "    from object_detection.metrics import coco_evaluation\n",
      "  File \"/tensorflow/models/research/object_detection/metrics/coco_evaluation.py\", line 20, in <module>\n",
      "    from object_detection.metrics import coco_tools\n",
      "  File \"/tensorflow/models/research/object_detection/metrics/coco_tools.py\", line 47, in <module>\n",
      "    from pycocotools import coco\n",
      "  File \"/tensorflow/models/research/pycocotools/coco.py\", line 49, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f2fe2ee27d0>) includes params argument, but params are not passed to Estimator.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /tensorflow/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.experimental.parallel_interleave(...)`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /tensorflow/models/research/object_detection/core/preprocessor.py:1218: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse the `axis` argument instead\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /tensorflow/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_0/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_0/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 576, 273]], model variable shape: [[1, 1, 576, 6]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_1/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_1/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1280, 546]], model variable shape: [[1, 1, 1280, 12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_2/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_2/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_3/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_3/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_4/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_4/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_5/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [BoxPredictor_5/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.\u001b[0m\n",
      "\u001b[34mWARNING:root:Variable [global_step] is not available in checkpoint\u001b[0m\n",
      "\u001b[34m2020-06-02 05:07:02.711267: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "algorithm_name = 'wpi-cpu'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameters:\n",
    "    epochs -> int: number of training steps. Training time is proportional to this number. default = 1000\n",
    "    batch_size -> int: size of a batch of training images. default = 32\n",
    "    train_max_run -> int: max seconds a training job can run for. default = 43200\n",
    "\"\"\"\n",
    "hyperparameters = {'epochs': 200,\n",
    "                   'batch_size': 32}\n",
    "\n",
    "ecr_image = \"118451457254.dkr.ecr.us-east-1.amazonaws.com/{}:latest\".format(algorithm_name)\n",
    "\n",
    "# The estimator object, using our notebook, training instance, the ECR image, and the specified training steps\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_max_run=43200)\n",
    "\n",
    "# Change this bucket if you want to train with your own data. The WPILib bucket contains thousands of high quality labeled images.\n",
    "# s3://wpilib\n",
    "estimator.fit(\"s3://wpilib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "You can download your trained model after the above step tells you \"Training job completed\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
